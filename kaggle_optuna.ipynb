{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RiWkEhun81B2"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets scikit-learn optuna --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uCyOK7LK9GuA"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svHH79Na_SRg",
        "outputId": "d9430eb0-338d-47c3-ee34-812032384f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: redeyedraven\n",
            "Your Kaggle Key: ··········\n",
            "Downloading GiveMeSomeCredit.zip to ./GiveMeSomeCredit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.16M/5.16M [00:00<00:00, 5.45MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting archive ./GiveMeSomeCredit/GiveMeSomeCredit.zip to ./GiveMeSomeCredit\n"
          ]
        }
      ],
      "source": [
        "resource_url= 'https://www.kaggle.com/competitions/GiveMeSomeCredit/data'\n",
        "od.download(resource_url)\n",
        "os.chdir('GiveMeSomeCredit')\n",
        "\n",
        "train_set= pd.read_csv('cs-training.csv')\n",
        "test_set= pd.read_csv('cs-test.csv')\n",
        "sample_entry= pd.read_csv('sampleEntry.csv')\n",
        "\n",
        "input_features= train_set.iloc[:, 2:].columns.to_list()\n",
        "target_label= train_set.iloc[:, 1].to_frame().columns.to_list()\n",
        "\n",
        "input_features_dataframe= train_set[input_features]\n",
        "median_imputer= SimpleImputer(strategy= 'median')\n",
        "imputed_data= median_imputer.fit_transform(input_features_dataframe)\n",
        "imputed_features_dataframe= pd.DataFrame(data= imputed_data, columns= input_features_dataframe.columns)\n",
        "\n",
        "x= imputed_features_dataframe[input_features]\n",
        "y= train_set[target_label]\n",
        "\n",
        "#x_train, x_validation, y_train, y_validation= train_test_split(x, y.values.ravel(), test_size= 0.25, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-hIWWEoHR-yY"
      },
      "outputs": [],
      "source": [
        "#  Testing Cross Validaiton\n",
        "\n",
        "def objective(trial):\n",
        "  parameters= {'objective'        :'binary',\n",
        "              'metric'            :'binary_logloss',\n",
        "              'boosting_type'     :trial.suggest_categorical('boosting_type', ['gbdt', 'dart']),\n",
        "              'num_leaves'        :trial.suggest_int('num_leaves', 2, 256),\n",
        "              'learning_rate'     :trial.suggest_float('learning_rate', 0.001, 0.5),\n",
        "              'feature_fraction'  :trial.suggest_float('feature_fraction', 0.1, 1.0),\n",
        "              'bagging_fraction'  :trial.suggest_float('bagging_fraction', 0.1, 1.0),\n",
        "              'bagging_freq'      :trial.suggest_int('bagging_freq', 1, 10),\n",
        "              'reg_alpha'         :trial.suggest_float('reg_alpha', 1e-8, 10.0, log= True),\n",
        "              'reg_lambda'        :trial.suggest_float('reg_lambda', 1e-8, 10.0, log= True),\n",
        "              'min_child_samples' :trial.suggest_int('min_child_samples', 5, 100)}\n",
        "\n",
        "  LGBM= LGBMClassifier(**parameters,\n",
        "                       force_col_wise= True)\n",
        "\n",
        "  scores= cross_val_score(LGBM,\n",
        "                          x,\n",
        "                          y,\n",
        "                          n_jobs= -1,\n",
        "                          cv= 5,\n",
        "                          scoring= 'accuracy')\n",
        "  accuracy= scores.mean()\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEYz31awTIff"
      },
      "outputs": [],
      "source": [
        "study= optuna.create_study(direction= 'maximize')\n",
        "study.optimize(objective, n_trials= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC0Xq3oaTOL3",
        "outputId": "7f8d1457-0a22-4463-ef9c-f55d587a42c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  Value (Accuracy):  0.9376866666666667\n",
            "  Params: \n",
            "    boosting_type: dart\n",
            "    num_leaves: 34\n",
            "    learning_rate: 0.12790357571059024\n",
            "    feature_fraction: 0.491139423521851\n",
            "    bagging_fraction: 0.5928349766122926\n",
            "    bagging_freq: 4\n",
            "    reg_alpha: 6.8372689571593e-05\n",
            "    reg_lambda: 0.0017614372265715404\n",
            "    min_child_samples: 97\n"
          ]
        }
      ],
      "source": [
        "best_model= study.best_trial\n",
        "print(\"Best trial:\")\n",
        "print(\"  Value (Accuracy): \", best_model.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in best_model.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dXo_UNnN0o"
      },
      "source": [
        "# Final Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "apMyzjyzaIB6"
      },
      "outputs": [],
      "source": [
        "test_set_input_features= test_set.iloc[:, 2:]\n",
        "\n",
        "imputed_test_data= median_imputer.fit_transform(test_set_input_features)\n",
        "imputed_test_features_dataframe= pd.DataFrame(data= imputed_test_data, columns= test_set_input_features.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "OdDFrGZ4ngPM"
      },
      "outputs": [],
      "source": [
        "final_model= LGBMClassifier(boosting_type= 'dart',\n",
        "                            num_leaves= 34,\n",
        "                            learning_rate= 0.12790357571059024,\n",
        "                            feature_fraction= 0.491139423521851,\n",
        "                            bagging_fraction= 0.5928349766122926,\n",
        "                            bagging_freq= 4,\n",
        "                            reg_alpha= 6.8372689571593e-05,\n",
        "                            reg_lambda= 0.0017614372265715404,\n",
        "                            min_child_samples= 97,\n",
        "                            force_col_wise= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "KtovIefQoE4o",
        "outputId": "af34007e-d0c6-48ad-9fb7-e6f0928adb3a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.491139423521851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.491139423521851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5928349766122926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5928349766122926\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.491139423521851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.491139423521851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5928349766122926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5928349766122926\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Info] Number of positive: 10026, number of negative: 139974\n",
            "[LightGBM] [Info] Total Bins 978\n",
            "[LightGBM] [Info] Number of data points in the train set: 150000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.066840 -> initscore=-2.636275\n",
            "[LightGBM] [Info] Start training from score -2.636275\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.5928349766122926, bagging_freq=4,\n",
              "               boosting_type=&#x27;dart&#x27;, feature_fraction=0.491139423521851,\n",
              "               force_col_wise=True, learning_rate=0.12790357571059024,\n",
              "               min_child_samples=97, num_leaves=34,\n",
              "               reg_alpha=6.8372689571593e-05, reg_lambda=0.0017614372265715404)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(bagging_fraction=0.5928349766122926, bagging_freq=4,\n",
              "               boosting_type=&#x27;dart&#x27;, feature_fraction=0.491139423521851,\n",
              "               force_col_wise=True, learning_rate=0.12790357571059024,\n",
              "               min_child_samples=97, num_leaves=34,\n",
              "               reg_alpha=6.8372689571593e-05, reg_lambda=0.0017614372265715404)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.5928349766122926, bagging_freq=4,\n",
              "               boosting_type='dart', feature_fraction=0.491139423521851,\n",
              "               force_col_wise=True, learning_rate=0.12790357571059024,\n",
              "               min_child_samples=97, num_leaves=34,\n",
              "               reg_alpha=6.8372689571593e-05, reg_lambda=0.0017614372265715404)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_model.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp_vZ3ZOnYB2",
        "outputId": "16fae570-2527-442a-8626-d14b7b8b0c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.491139423521851, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.491139423521851\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5928349766122926, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5928349766122926\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n"
          ]
        }
      ],
      "source": [
        "final_model_prediction= final_model.predict_proba(imputed_test_features_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "hLfLrHRpoPrQ"
      },
      "outputs": [],
      "source": [
        "final_prediction_dataframe= sample_entry.copy()\n",
        "final_prediction_dataframe.set_index('Id', inplace= True)\n",
        "final_prediction_dataframe.Probability= final_model_prediction[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "f7plXHnnoxHY"
      },
      "outputs": [],
      "source": [
        "final_prediction_dataframe.to_csv('final_prediction.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo6jyA53o_-m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
